{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "zrJqruAEsfBA",
    "outputId": "aec74259-fb99-4dbd-e695-94c7acf74201"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "titanic_df = pd.read_csv('titanic_train.csv')\n",
    "titanic_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "MbYg9LhmsfBC",
    "outputId": "d1ab89d4-c059-4340-d3a1-d09a82d73217"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ### train 데이터 정보 ###  \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print('\\n ### train 데이터 정보 ###  \\n')\n",
    "print(titanic_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "-zHclzY-sfBD",
    "outputId": "4e166028-f2b1-41c6-af6c-f35fa87e7a3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 세트 Null 값 갯수  0\n"
     ]
    }
   ],
   "source": [
    "titanic_df['Age'].fillna(titanic_df['Age'].mean(),inplace=True)\n",
    "titanic_df['Cabin'].fillna('N',inplace=True)\n",
    "titanic_df['Embarked'].fillna('N',inplace=True)\n",
    "print('데이터 세트 Null 값 갯수 ',titanic_df.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "edOvfMb_sfBE",
    "outputId": "40a619c0-5bad-4c47-88e3-8f363243e7d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Sex 값 분포 :\n",
      " male      577\n",
      "female    314\n",
      "Name: Sex, dtype: int64\n",
      "\n",
      " Cabin 값 분포 :\n",
      " N              687\n",
      "C23 C25 C27      4\n",
      "G6               4\n",
      "B96 B98          4\n",
      "C22 C26          3\n",
      "              ... \n",
      "E34              1\n",
      "C7               1\n",
      "C54              1\n",
      "E36              1\n",
      "C148             1\n",
      "Name: Cabin, Length: 148, dtype: int64\n",
      "\n",
      " Embarked 값 분포 :\n",
      " S    644\n",
      "C    168\n",
      "Q     77\n",
      "N      2\n",
      "Name: Embarked, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(' Sex 값 분포 :\\n',titanic_df['Sex'].value_counts())\n",
    "print('\\n Cabin 값 분포 :\\n',titanic_df['Cabin'].value_counts())\n",
    "print('\\n Embarked 값 분포 :\\n',titanic_df['Embarked'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "3qplJvTfsfBF",
    "outputId": "da93c0a5-e0a5-4ea4-dbdf-55116450efd4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    N\n",
      "1    C\n",
      "2    N\n",
      "Name: Cabin, dtype: object\n"
     ]
    }
   ],
   "source": [
    "titanic_df['Cabin'] = titanic_df['Cabin'].str[:1]\n",
    "print(titanic_df['Cabin'].head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "wQRSsM24sfBF",
    "outputId": "728d60b0-3f08-4b57-973d-6cb8b05796fd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sex     Survived\n",
       "female  0            81\n",
       "        1           233\n",
       "male    0           468\n",
       "        1           109\n",
       "Name: Survived, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_df.groupby(['Sex','Survived'])['Survived'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "I97bGQohsfBG",
    "outputId": "65e7c800-cf8c-40f9-8db5-67a225a2ceaa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Sex', ylabel='Survived'>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(x='Sex', y = 'Survived', data=titanic_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "38uS_Lf8sfBG",
    "outputId": "ddf07acf-2aeb-4806-cfee-e319eee8ede7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Pclass', ylabel='Survived'>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(x='Pclass', y='Survived', hue='Sex', data=titanic_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "kP6VIkqVsfBH",
    "outputId": "1b85a74c-b1ab-47e3-e774-c396844e8624"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 입력 age에 따라 구분값을 반환하는 함수 설정. DataFrame의 apply lambda식에 사용. \n",
    "def get_category(age):\n",
    "    cat = ''\n",
    "    if age <= -1: cat = 'Unknown'\n",
    "    elif age <= 5: cat = 'Baby'\n",
    "    elif age <= 12: cat = 'Child'\n",
    "    elif age <= 18: cat = 'Teenager'\n",
    "    elif age <= 25: cat = 'Student'\n",
    "    elif age <= 35: cat = 'Young Adult'\n",
    "    elif age <= 60: cat = 'Adult'\n",
    "    else : cat = 'Elderly'\n",
    "    \n",
    "    return cat\n",
    "\n",
    "# 막대그래프의 크기 figure를 더 크게 설정 \n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "#X축의 값을 순차적으로 표시하기 위한 설정 \n",
    "group_names = ['Unknown', 'Baby', 'Child', 'Teenager', 'Student', 'Young Adult', 'Adult', 'Elderly']\n",
    "\n",
    "# lambda 식에 위에서 생성한 get_category( ) 함수를 반환값으로 지정. \n",
    "# get_category(X)는 입력값으로 'Age' 컬럼값을 받아서 해당하는 cat 반환\n",
    "titanic_df['Age_cat'] = titanic_df['Age'].apply(lambda x : get_category(x))\n",
    "sns.barplot(x='Age_cat', y = 'Survived', hue='Sex', data=titanic_df, order=group_names)\n",
    "titanic_df.drop('Age_cat', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "KLMVw-aFsfBI",
    "outputId": "aba59c91-afb2-4802-c903-f6467f0ac099"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name  Sex   Age  SibSp  Parch  \\\n",
       "0                            Braund, Mr. Owen Harris    1  22.0      1      0   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...    0  38.0      1      0   \n",
       "2                             Heikkinen, Miss. Laina    0  26.0      0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)    0  35.0      1      0   \n",
       "4                           Allen, Mr. William Henry    1  35.0      0      0   \n",
       "\n",
       "             Ticket     Fare  Cabin  Embarked  \n",
       "0         A/5 21171   7.2500      7         3  \n",
       "1          PC 17599  71.2833      2         0  \n",
       "2  STON/O2. 3101282   7.9250      7         3  \n",
       "3            113803  53.1000      2         3  \n",
       "4            373450   8.0500      7         3  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "def encode_features(dataDF):\n",
    "    features = ['Cabin', 'Sex', 'Embarked']\n",
    "    for feature in features:\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        le = le.fit(dataDF[feature])\n",
    "        dataDF[feature] = le.transform(dataDF[feature])\n",
    "        \n",
    "    return dataDF\n",
    "\n",
    "titanic_df = encode_features(titanic_df)\n",
    "titanic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "vSYVL2kssfBJ"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Null 처리 함수\n",
    "def fillna(df):\n",
    "    df['Age'].fillna(df['Age'].mean(),inplace=True)\n",
    "    df['Cabin'].fillna('N',inplace=True)\n",
    "    df['Embarked'].fillna('N',inplace=True)\n",
    "    df['Fare'].fillna(0,inplace=True)\n",
    "    return df\n",
    "\n",
    "# 머신러닝 알고리즘에 불필요한 속성 제거\n",
    "def drop_features(df):\n",
    "    df.drop(['PassengerId','Name','Ticket'],axis=1,inplace=True)\n",
    "    return df\n",
    "\n",
    "# 레이블 인코딩 수행. \n",
    "def format_features(df):\n",
    "    df['Cabin'] = df['Cabin'].str[:1]\n",
    "    features = ['Cabin','Sex','Embarked']\n",
    "    for feature in features:\n",
    "        le = LabelEncoder()\n",
    "        le = le.fit(df[feature])\n",
    "        df[feature] = le.transform(df[feature])\n",
    "    return df\n",
    "\n",
    "# 앞에서 설정한 Data Preprocessing 함수 호출\n",
    "def transform_features(df):\n",
    "    df = fillna(df)\n",
    "    df = drop_features(df)\n",
    "    df = format_features(df)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "8fIEyqiNsfBJ"
   },
   "outputs": [],
   "source": [
    "# 원본 데이터를 재로딩 하고, feature데이터 셋과 Label 데이터 셋 추출. \n",
    "titanic_df = pd.read_csv('./titanic_train.csv')\n",
    "y_titanic_df = titanic_df['Survived']\n",
    "X_titanic_df= titanic_df.drop('Survived',axis=1)\n",
    "\n",
    "X_titanic_df = transform_features(X_titanic_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "YBZUpaWzsfBK"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test=train_test_split(X_titanic_df, y_titanic_df, \\\n",
    "                                                  test_size=0.2, random_state=11)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "izTJtRblsfBK",
    "outputId": "33b742a9-02d3-48a3-8671-d39f1f7dd0c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier 정확도: 0.7877\n",
      "RandomForestClassifier 정확도:0.8547\n",
      "LogisticRegression 정확도: 0.8492\n",
      "SVM 정확도: 0.8492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KI\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 결정트리, Random Forest, 로지스틱 회귀를 위한 사이킷런 Classifier 클래스 생성\n",
    "dt_clf = DecisionTreeClassifier(random_state=11)\n",
    "rf_clf = RandomForestClassifier(random_state=11)\n",
    "lr_clf = LogisticRegression()\n",
    "svm_svc = SVC() ##추가해보자.!!\n",
    "\n",
    "# DecisionTreeClassifier 학습/예측/평가\n",
    "dt_clf.fit(X_train , y_train)\n",
    "dt_pred = dt_clf.predict(X_test)\n",
    "print('DecisionTreeClassifier 정확도: {0:.4f}'.format(accuracy_score(y_test, dt_pred)))\n",
    "\n",
    "# RandomForestClassifier 학습/예측/평가\n",
    "rf_clf.fit(X_train , y_train)\n",
    "rf_pred = rf_clf.predict(X_test)\n",
    "print('RandomForestClassifier 정확도:{0:.4f}'.format(accuracy_score(y_test, rf_pred)))\n",
    "\n",
    "# LogisticRegression 학습/예측/평가\n",
    "lr_clf.fit(X_train , y_train)\n",
    "lr_pred = lr_clf.predict(X_test)\n",
    "print('LogisticRegression 정확도: {0:.4f}'.format(accuracy_score(y_test, lr_pred)))\n",
    "\n",
    "\n",
    "# SVM 학습/예측/평가\n",
    "svm_svc.fit(X_train , y_train)\n",
    "svm_pred = lr_clf.predict(X_test)\n",
    "print('SVM 정확도: {0:.4f}'.format(accuracy_score(y_test, lr_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 교차검증 Kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KFold(n_splits=5, random_state=None, shuffle=False)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kfold= KFold(n_splits = 5 )\n",
    "kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "for iter_count , (train_index , test_index) in enumerate(kfold.split(X_titanic_df)):\n",
    "        print(iter_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 8)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_titanic_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "----------\n",
      "[179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196\n",
      " 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214\n",
      " 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232\n",
      " 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250\n",
      " 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268\n",
      " 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286\n",
      " 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304\n",
      " 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322\n",
      " 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340\n",
      " 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358\n",
      " 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376\n",
      " 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394\n",
      " 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412\n",
      " 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430\n",
      " 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448\n",
      " 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466\n",
      " 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484\n",
      " 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502\n",
      " 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520\n",
      " 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538\n",
      " 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556\n",
      " 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574\n",
      " 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592\n",
      " 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610\n",
      " 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628\n",
      " 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646\n",
      " 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664\n",
      " 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682\n",
      " 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700\n",
      " 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718\n",
      " 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736\n",
      " 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754\n",
      " 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772\n",
      " 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790\n",
      " 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808\n",
      " 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826\n",
      " 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844\n",
      " 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862\n",
      " 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880\n",
      " 881 882 883 884 885 886 887 888 889 890]\n",
      "1\n",
      "----------\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
      " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 357\n",
      " 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375\n",
      " 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393\n",
      " 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411\n",
      " 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429\n",
      " 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447\n",
      " 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465\n",
      " 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483\n",
      " 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501\n",
      " 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519\n",
      " 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537\n",
      " 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555\n",
      " 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573\n",
      " 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591\n",
      " 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609\n",
      " 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627\n",
      " 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645\n",
      " 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663\n",
      " 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681\n",
      " 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699\n",
      " 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717\n",
      " 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735\n",
      " 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753\n",
      " 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771\n",
      " 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789\n",
      " 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807\n",
      " 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825\n",
      " 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843\n",
      " 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861\n",
      " 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879\n",
      " 880 881 882 883 884 885 886 887 888 889 890]\n",
      "2\n",
      "----------\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
      " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
      " 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n",
      " 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n",
      " 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n",
      " 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251\n",
      " 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269\n",
      " 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287\n",
      " 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305\n",
      " 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323\n",
      " 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341\n",
      " 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 535 536 537\n",
      " 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555\n",
      " 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573\n",
      " 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591\n",
      " 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609\n",
      " 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627\n",
      " 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645\n",
      " 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663\n",
      " 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681\n",
      " 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699\n",
      " 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717\n",
      " 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735\n",
      " 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753\n",
      " 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771\n",
      " 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789\n",
      " 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807\n",
      " 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825\n",
      " 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843\n",
      " 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861\n",
      " 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879\n",
      " 880 881 882 883 884 885 886 887 888 889 890]\n",
      "3\n",
      "----------\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
      " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
      " 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n",
      " 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n",
      " 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n",
      " 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251\n",
      " 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269\n",
      " 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287\n",
      " 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305\n",
      " 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323\n",
      " 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341\n",
      " 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359\n",
      " 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377\n",
      " 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395\n",
      " 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413\n",
      " 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431\n",
      " 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449\n",
      " 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467\n",
      " 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485\n",
      " 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503\n",
      " 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521\n",
      " 522 523 524 525 526 527 528 529 530 531 532 533 534 713 714 715 716 717\n",
      " 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735\n",
      " 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753\n",
      " 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771\n",
      " 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789\n",
      " 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807\n",
      " 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825\n",
      " 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843\n",
      " 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861\n",
      " 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879\n",
      " 880 881 882 883 884 885 886 887 888 889 890]\n",
      "4\n",
      "----------\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
      " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
      " 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n",
      " 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n",
      " 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n",
      " 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251\n",
      " 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269\n",
      " 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287\n",
      " 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305\n",
      " 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323\n",
      " 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341\n",
      " 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359\n",
      " 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377\n",
      " 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395\n",
      " 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413\n",
      " 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431\n",
      " 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449\n",
      " 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467\n",
      " 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485\n",
      " 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503\n",
      " 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521\n",
      " 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539\n",
      " 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557\n",
      " 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575\n",
      " 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593\n",
      " 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611\n",
      " 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629\n",
      " 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647\n",
      " 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665\n",
      " 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683\n",
      " 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701\n",
      " 702 703 704 705 706 707 708 709 710 711 712]\n"
     ]
    }
   ],
   "source": [
    "for iter_count , (train_index, test_index) in enumerate(kfold.split(X_titanic_df)):\n",
    "        print(iter_count) \n",
    "        print('----------')\n",
    "        print(train_index) \n",
    "        \n",
    "# 인덱스만 추출한것 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.        ,  1.        , 22.        , ...,  7.25      ,\n",
       "         7.        ,  3.        ],\n",
       "       [ 1.        ,  0.        , 38.        , ..., 71.2833    ,\n",
       "         2.        ,  0.        ],\n",
       "       [ 3.        ,  0.        , 26.        , ...,  7.925     ,\n",
       "         7.        ,  3.        ],\n",
       "       ...,\n",
       "       [ 1.        ,  0.        , 24.        , ..., 49.5042    ,\n",
       "         2.        ,  0.        ],\n",
       "       [ 1.        ,  1.        , 29.69911765, ..., 26.55      ,\n",
       "         2.        ,  3.        ],\n",
       "       [ 1.        ,  1.        , 48.        , ..., 52.        ,\n",
       "         2.        ,  3.        ]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_titanic_df.values[train_index] #인덱스에 해당하는 rows들!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kfold 교차검증을 통해 최적이 모델을 찾아보자.(내가 구현해보자.)\n",
    "\n",
    "def exec_kfold(clf, folds=5):\n",
    "    # 폴드 세트를 5개인 KFold객체를 생성, 폴드 수만큼 예측결과 저장을 위한  리스트 객체 생성.\n",
    "    kfold = KFold(n_splits=folds)\n",
    "    scores = []\n",
    "    \n",
    "    # KFold 교차 검증 수행. \n",
    "    for iter_count , (train_index, test_index) in enumerate(kfold.split(X_titanic_df)):\n",
    "        # X_titanic_df 데이터에서 교차 검증별로 학습과 검증 데이터를 가리키는 index 생성\n",
    "        X_train, X_test = X_titanic_df.values[train_index], X_titanic_df.values[test_index]\n",
    "        y_train, y_test = y_titanic_df.values[train_index], y_titanic_df.values[test_index]\n",
    "        \n",
    "        # Classifier 학습, 예측, 정확도 계산 \n",
    "        clf.fit(X_train, y_train) \n",
    "        predictions = clf.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, predictions)\n",
    "        scores.append(accuracy)\n",
    "        print(\"교차 검증 {0} 정확도: {1:.4f}\".format(iter_count, accuracy))     \n",
    "    \n",
    "    # 5개 fold에서의 평균 정확도 계산. \n",
    "    mean_score = np.mean(scores)\n",
    "    print(\"평균 정확도: {0:.4f}\".format(mean_score)) \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "교차 검증 0 정확도: 0.7542\n",
      "교차 검증 1 정확도: 0.7809\n",
      "교차 검증 2 정확도: 0.7865\n",
      "교차 검증 3 정확도: 0.7697\n",
      "교차 검증 4 정확도: 0.8202\n",
      "평균 정확도: 0.7823\n"
     ]
    }
   ],
   "source": [
    "exec_kfold(dt_clf , folds=5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "교차 검증 0 정확도: 0.7989\n",
      "교차 검증 1 정확도: 0.7809\n",
      "교차 검증 2 정확도: 0.7753\n",
      "교차 검증 3 정확도: 0.7584\n",
      "교차 검증 4 정확도: 0.8202\n",
      "평균 정확도: 0.7867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KI\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\KI\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\KI\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\KI\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\KI\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "exec_kfold(lr_clf , folds=5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "교차 검증 0 정확도: 0.7933\n",
      "교차 검증 1 정확도: 0.8090\n",
      "교차 검증 2 정확도: 0.8371\n",
      "교차 검증 3 정확도: 0.7753\n",
      "교차 검증 4 정확도: 0.8596\n",
      "평균 정확도: 0.8148\n"
     ]
    }
   ],
   "source": [
    "exec_kfold(rf_clf , folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "교차 검증 0 정확도: 0.5866\n",
      "교차 검증 1 정확도: 0.6685\n",
      "교차 검증 2 정확도: 0.6685\n",
      "교차 검증 3 정확도: 0.6629\n",
      "교차 검증 4 정확도: 0.7079\n",
      "평균 정확도: 0.6589\n"
     ]
    }
   ],
   "source": [
    "exec_kfold(svm_svc , folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최종적으로 제일 높은 모델로 함수화\n",
    "def exec_kfold(clf, folds=5):\n",
    "    # 폴드 세트를 5개인 KFold객체를 생성, 폴드 수만큼 예측결과 저장을 위한  리스트 객체 생성.\n",
    "    kfold = KFold(n_splits=folds)\n",
    "    scores = []\n",
    "    \n",
    "    # KFold 교차 검증 수행. \n",
    "    for iter_count , (train_index, test_index) in enumerate(kfold.split(X_titanic_df)):\n",
    "        # X_titanic_df 데이터에서 교차 검증별로 학습과 검증 데이터를 가리키는 index 생성\n",
    "        X_train, X_test = X_titanic_df.values[train_index], X_titanic_df.values[test_index]\n",
    "        y_train, y_test = y_titanic_df.values[train_index], y_titanic_df.values[test_index]\n",
    "        \n",
    "        # Classifier 학습, 예측, 정확도 계산 \n",
    "        clf.fit(X_train, y_train) \n",
    "        predictions = clf.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, predictions)\n",
    "        scores.append(accuracy)\n",
    "        print(\"교차 검증 {0} 정확도: {1:.4f}\".format(iter_count, accuracy))     \n",
    "    \n",
    "    # 5개 fold에서의 평균 정확도 계산. \n",
    "    mean_score = np.mean(scores)\n",
    "    print(\"평균 정확도: {0:.4f}\".format(mean_score)) \n",
    "    return mean_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_result = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "교차 검증 0 정확도: 0.7542\n",
      "교차 검증 1 정확도: 0.7809\n",
      "교차 검증 2 정확도: 0.7865\n",
      "교차 검증 3 정확도: 0.7697\n",
      "교차 검증 4 정확도: 0.8202\n",
      "평균 정확도: 0.7823\n"
     ]
    }
   ],
   "source": [
    "dt_result = exec_kfold(dt_clf , folds=5) \n",
    "dt_result\n",
    "all_result.append(dt_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "교차 검증 0 정확도: 0.6000\n",
      "교차 검증 1 정확도: 0.6742\n",
      "교차 검증 2 정확도: 0.6629\n",
      "교차 검증 3 정확도: 0.6742\n",
      "교차 검증 4 정확도: 0.6517\n",
      "교차 검증 5 정확도: 0.7079\n",
      "교차 검증 6 정확도: 0.6742\n",
      "교차 검증 7 정확도: 0.7303\n",
      "교차 검증 8 정확도: 0.7303\n",
      "교차 검증 9 정확도: 0.6854\n",
      "평균 정확도: 0.6791\n"
     ]
    }
   ],
   "source": [
    "svm_result = exec_kfold(svm_svc , folds=10) \n",
    "svm_result\n",
    "all_result.append(svm_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "교차 검증 0 정확도: 0.7778\n",
      "교차 검증 1 정확도: 0.7865\n",
      "교차 검증 2 정확도: 0.7753\n",
      "교차 검증 3 정확도: 0.8202\n",
      "교차 검증 4 정확도: 0.8315\n",
      "교차 검증 5 정확도: 0.8202\n",
      "교차 검증 6 정확도: 0.7865\n",
      "교차 검증 7 정확도: 0.7865\n",
      "교차 검증 8 정확도: 0.8764\n",
      "교차 검증 9 정확도: 0.8539\n",
      "평균 정확도: 0.8115\n"
     ]
    }
   ],
   "source": [
    "rf_result = exec_kfold(rf_clf , folds=10) \n",
    "rf_result\n",
    "all_result.append(rf_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KI\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\KI\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\KI\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\KI\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\KI\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\KI\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\KI\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\KI\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "교차 검증 0 정확도: 0.8000\n",
      "교차 검증 1 정확도: 0.8090\n",
      "교차 검증 2 정확도: 0.7753\n",
      "교차 검증 3 정확도: 0.7865\n",
      "교차 검증 4 정확도: 0.7865\n",
      "교차 검증 5 정확도: 0.7640\n",
      "교차 검증 6 정확도: 0.7528\n",
      "교차 검증 7 정확도: 0.7753\n",
      "교차 검증 8 정확도: 0.8315\n",
      "교차 검증 9 정확도: 0.7865\n",
      "평균 정확도: 0.7867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KI\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\KI\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "lr_result = exec_kfold(lr_clf,folds =10)\n",
    "lr_result\n",
    "all_result.append(lr_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_max(all_list):\n",
    "    print(all_list)\n",
    "    max_value = 0\n",
    "    for model_result in all_list:\n",
    "        if(model_result > max_value):\n",
    "            max_value = model_result\n",
    "        print('현재까지의 max값 >> ' , max_value)\n",
    "    return max_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.782298662984119, 0.6791011235955057, 0.8114856429463171, 0.7867415730337078]\n",
      "현재까지의 max값 >>  0.782298662984119\n",
      "현재까지의 max값 >>  0.782298662984119\n",
      "현재까지의 max값 >>  0.8114856429463171\n",
      "현재까지의 max값 >>  0.8114856429463171\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8114856429463171"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_result = all_max(all_result)\n",
    "max_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_max2(all_list):\n",
    "    max_value = 0\n",
    "    index = 0\n",
    "    for i, model_result in enumerate(all_list):\n",
    "        if(model_result > max_value):\n",
    "            max_value = model_result\n",
    "            index = i\n",
    "        print('현재까지의 max값 >> ' , max_value)\n",
    "    return max_value, index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재까지의 max값 >>  0.782298662984119\n",
      "현재까지의 max값 >>  0.782298662984119\n",
      "현재까지의 max값 >>  0.8114856429463171\n",
      "현재까지의 max값 >>  0.8114856429463171\n",
      "(0.8114856429463171, 2)\n"
     ]
    }
   ],
   "source": [
    "max_result2 = all_max2(all_result)\n",
    "print(max_result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = ['decision tree', 'svm10', 'random forest']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최적의 model은  random forest\n"
     ]
    }
   ],
   "source": [
    "print('최적의 model은 ', model_list[max_result2[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [dt_clf,rf_clf,lr_clf,svm_svc]\n",
    "model_list = ['DecisionTree' , 'RandomForest' , 'LogisticRegression' , 'SVC']\n",
    "folds = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-fold 를 한번으로 묶어보세요\n",
    "def callKFold_all(models,model_list,folds):\n",
    "    score = []\n",
    "    for i in range(4):\n",
    "        model_acc = exec_kfold(models[i],folds)\n",
    "        score.append(model_acc)\n",
    "    print(score)\n",
    "    \n",
    "    max_score = np.max(score)\n",
    "    idx = score.index(max_score)\n",
    "    best_model = models[idx]\n",
    "    print('==========')\n",
    "    print('최적의 modeld은' , models[idx],'최대 accuracy는',max_score)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "교차 검증 0 정확도: 0.7542\n",
      "교차 검증 1 정확도: 0.7809\n",
      "교차 검증 2 정확도: 0.7865\n",
      "교차 검증 3 정확도: 0.7697\n",
      "교차 검증 4 정확도: 0.8202\n",
      "평균 정확도: 0.7823\n",
      "교차 검증 0 정확도: 0.7933\n",
      "교차 검증 1 정확도: 0.8090\n",
      "교차 검증 2 정확도: 0.8371\n",
      "교차 검증 3 정확도: 0.7753\n",
      "교차 검증 4 정확도: 0.8596\n",
      "평균 정확도: 0.8148\n",
      "교차 검증 0 정확도: 0.7989\n",
      "교차 검증 1 정확도: 0.7809\n",
      "교차 검증 2 정확도: 0.7753\n",
      "교차 검증 3 정확도: 0.7584\n",
      "교차 검증 4 정확도: 0.8202\n",
      "평균 정확도: 0.7867\n",
      "교차 검증 0 정확도: 0.5866\n",
      "교차 검증 1 정확도: 0.6685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KI\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\KI\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\KI\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\KI\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\KI\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "교차 검증 2 정확도: 0.6685\n",
      "교차 검증 3 정확도: 0.6629\n",
      "교차 검증 4 정확도: 0.7079\n",
      "평균 정확도: 0.6589\n",
      "[0.782298662984119, 0.8148389931579938, 0.7867428284476806, 0.658891469462055]\n",
      "==========\n",
      "최적의 modeld은 RandomForestClassifier(random_state=11) 최대 accuracy는 0.8148389931579938\n"
     ]
    }
   ],
   "source": [
    "callKFold_all(models,model_list,folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "교차 검증 0 정확도: 0.7430\n",
      "교차 검증 1 정확도: 0.7753\n",
      "교차 검증 2 정확도: 0.7921\n",
      "교차 검증 3 정확도: 0.7865\n",
      "교차 검증 4 정확도: 0.8427\n",
      "평균 정확도: 0.7879\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(dt_clf, X_titanic_df , y_titanic_df , cv=5) # cv=5 = folds 값\n",
    "for iter_count,accuracy in enumerate(scores): # scores 평균이아니고 list ?\n",
    "    print(\"교차 검증 {0} 정확도: {1:.4f}\".format(iter_count, accuracy))  # format 함수 검색\n",
    "    # \"교차 검증 {0} 정확도: {1:.4f}\" , format의 형태로 봤을때 작용된다.\n",
    "    # \"교차 검증 {0} 은 ,.format(iter_count의 첫번째 부분을 실행  /정확도: {1:.4f}\" 는 accuracy)) 2번째 부분을 실행 0.4f 는 소수점 4자리까지만 보여줘라\n",
    "print(\"평균 정확도: {0:.4f}\".format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(scores) # ndarry는 for문 돌릴수있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV 최적 하이퍼 파라미터 : {'max_depth': 3, 'min_samples_leaf': 5, 'min_samples_split': 2}\n",
      "GridSearchCV 최고 정확도: 0.7992\n",
      "테스트 세트에서의 DecisionTreeClassifier 정확도 : 0.8715\n"
     ]
    }
   ],
   "source": [
    "parameters = {'max_depth':[2,3,5,10],'min_samples_split':[2,3,5], 'min_samples_leaf':[1,5,8]}\n",
    "\n",
    "grid_dclf = GridSearchCV(dt_clf , param_grid=parameters , scoring='accuracy' , cv=5)\n",
    "grid_dclf.fit(X_train , y_train)\n",
    "\n",
    "print('GridSearchCV 최적 하이퍼 파라미터 :',grid_dclf.best_params_)\n",
    "print('GridSearchCV 최고 정확도: {0:.4f}'.format(grid_dclf.best_score_))\n",
    "best_dclf = grid_dclf.best_estimator_\n",
    "\n",
    "# GridSearchCV의 최적 하이퍼 파라미터로 학습된 Estimator로 예측 및 평가 수행. \n",
    "dpredictions = best_dclf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test,dpredictions)\n",
    "print('테스트 세트에서의 DecisionTreeClassifier 정확도 : {0:.4f}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0,\n",
       "       1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred= best_dclf.predict(X_test)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8715083798882681"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy =accuracy_score(y_test,pred)\n",
    "accuracy\n",
    "\n",
    "# 테스트 데이터가 더높은 accaccuracy 나오는게 더좋은 모델이다."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "2.6 사이킷런으로 수행하는 타이타닉 생존자 예측 .ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
